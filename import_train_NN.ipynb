{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load different models already pretrained from imagenet\n",
    "\n",
    "alexnet = models.alexnet(weights=\"IMAGENET1K_V1\")\n",
    "efficientnet = models.efficientnet_b7(weights=\"IMAGENET1K_V1\")\n",
    "vgg_19 = models.vgg19(weights='IMAGENET1K_V1')\n",
    "# inception_v3 = models.inception_v3(weights=\"IMAGENET1K_V1\") # size of input 299 * 299 instead of 224 * 224\n",
    "resnet = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "selected_models = {'resnet': resnet, 'alexnet': alexnet, 'efficientnet_b7':efficientnet, 'vgg_19':vgg_19}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the last layer of those networks to a fully connected layer with only 15 outputs ( for our 15 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before modification : Linear(in_features=2048, out_features=1000, bias=True)\n",
      "after modification : Linear(in_features=2048, out_features=15, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(f\"before modification : {selected_models['resnet'].fc}\")\n",
    "for key in selected_models.keys():\n",
    "    model = selected_models[key]\n",
    "    # set the learning of all the previous layers to false \n",
    "    # (already extracting the image features from their previous training)\n",
    "    for param in selected_models[key].parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # get last_layer size to fully connect our last decision layer\n",
    "    last_layer = [key for key in model.state_dict().keys()][-2]\n",
    "    last_layer_size = model.state_dict()[last_layer].shape[-1]\n",
    "    try:\n",
    "        selected_models[key].classifier = nn.Sequential(*list(model.classifier)[:-1], nn.Linear(last_layer_size, 15))\n",
    "    except Exception:\n",
    "        selected_models[key].fc = nn.Linear(last_layer_size, 15)\n",
    "\n",
    "print(f\"after modification : {selected_models['resnet'].fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    0: 'badminton',\n",
    "    1: 'baseball',\n",
    "    2: 'basketball',\n",
    "    3: 'boxing',\n",
    "    4: 'cricket',\n",
    "    5: 'football',\n",
    "    6: 'gymnastics',\n",
    "    7: 'hockey',\n",
    "    8: 'swimming',\n",
    "    9: 'table_tennis',\n",
    "    10: 'tennis',\n",
    "    11: 'volleyball',\n",
    "    12: 'weight_lifting',\n",
    "    13: 'wrestling',\n",
    "    14: 'wwe'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform images into tensor to input them into the convolutional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_image = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform every image to make a dataset of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10303, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/data.csv\") # path to images\n",
    "y = torch.as_tensor(df['label'].values)\n",
    "image_paths = df['path']\n",
    "images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    try:\n",
    "        img = Image.open(path)\n",
    "        images.append(preprocess_image(img.convert('RGB')))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "X = torch.stack(images)\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare the batch function to separate training data into batch of a certain size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 224, 224]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(X, y, batch_size, iteration):\n",
    "    start = batch_size * iteration\n",
    "    end = (batch_size) * (iteration + 1)\n",
    "    if end > X.shape[0]:\n",
    "        end = X.shape[0]\n",
    "    return X[start:end, :, :, :], y[start:end]\n",
    "\n",
    "batch_x, batch_y = get_batch(X, y, 50, 0)\n",
    "print(batch_x.shape, batch_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split datasets into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7727, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_val_dataset(X, y, testing_size=0.25):\n",
    "    train_idx, test_idx = train_test_split(list(range(X.shape[0])), test_size=testing_size)\n",
    "    datasets = {}\n",
    "    datasets['X_train'] = X[train_idx,:,:,:]\n",
    "    datasets['X_test'] = X[test_idx,:,:,:]\n",
    "    datasets['y_train'] = y[train_idx]\n",
    "    datasets['y_test'] = y[test_idx]\n",
    "\n",
    "    return datasets\n",
    "\n",
    "datasets = train_val_dataset(X, y, 0.25)\n",
    "print(datasets['X_train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(datasets, model, criterion, optimizer, batch_size = 100, num_epochs=5):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    accuracies = {}\n",
    "\n",
    "    X_train, y_train, X_test, y_test = datasets['X_train'], datasets['y_train'], datasets['X_test'], datasets['y_test']\n",
    "\n",
    "    batch_count = (X_train.shape[0] // batch_size) + 1\n",
    "    batch_test_count = (X_test.shape[0] // batch_size) + 1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        # training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for num_batch in range(batch_count):\n",
    "            if (num_batch % 15 == 0):\n",
    "                print(f'batch train : {num_batch}/{batch_count}')\n",
    "            inputs, labels = get_batch(X_train, y_train, batch_size, num_batch)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "                # backward + optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "        \n",
    "        epoch_train_loss = running_loss / datasets[f'X_train'].shape[0]\n",
    "        epoch_train_acc = running_corrects / datasets[f'X_train'].shape[0]\n",
    "\n",
    "        # testing set\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for num_batch in range(batch_test_count):\n",
    "            if (num_batch % 15 == 0):\n",
    "                print(f'batch test : {num_batch}/{batch_test_count}')\n",
    "            inputs, labels = get_batch(X_test, y_test, batch_size, num_batch)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        epoch_test_loss = running_loss / datasets[f'X_test'].shape[0]\n",
    "        epoch_test_acc = running_corrects / datasets[f'X_test'].shape[0]\n",
    "\n",
    "        accuracies[epoch] = {'train accuracy' : epoch_train_acc.item(), \n",
    "                            'test accuracy' : epoch_test_acc.item(),\n",
    "                            'train loss': epoch_train_loss,\n",
    "                            'test loss': epoch_test_loss}\n",
    "\n",
    "        # deep copy the model if better\n",
    "        if epoch_test_acc > best_acc:\n",
    "            best_acc = epoch_test_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, accuracies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all the models with 5 epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnet_b7\n",
      "Epoch 0/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 1/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 2/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 3/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 4/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Training complete in 541m 28s\n",
      "Best val Acc: 0.698758\n",
      "vgg_19\n",
      "Epoch 0/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 1/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 2/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 3/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Epoch 4/4\n",
      "batch train : 0/155\n",
      "batch train : 15/155\n",
      "batch train : 30/155\n",
      "batch train : 45/155\n",
      "batch train : 60/155\n",
      "batch train : 75/155\n",
      "batch train : 90/155\n",
      "batch train : 105/155\n",
      "batch train : 120/155\n",
      "batch train : 135/155\n",
      "batch train : 150/155\n",
      "batch test : 0/52\n",
      "batch test : 15/52\n",
      "batch test : 30/52\n",
      "batch test : 45/52\n",
      "Training complete in 410m 10s\n",
      "Best val Acc: 0.806289\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model_accuracies = {}\n",
    "\n",
    "for model_name, model in selected_models.items():\n",
    "    if model_name != 'resnet' and model_name != 'alexnet':\n",
    "        print(model_name)\n",
    "        optimizer_ft = optim.Adam(model.parameters(), lr=0.01)\n",
    "        model = model.to(device)\n",
    "        model_opti, model_accuracy = train_model(datasets, model, criterion, optimizer_ft, batch_size=50, num_epochs=5)\n",
    "        model_scripted = torch.jit.script(model_opti) # Export to TorchScript\n",
    "        model_accuracies[model_name] = model_accuracy\n",
    "        model_scripted.save(f'./models/{model_name}.pt') # Save\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('models_accuracies.txt', 'w') as f:\n",
    "    f.write(json.dumps(model_accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (tags/v3.8.9:a743f81, Apr  6 2021, 14:02:34) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42ab0bb38a78ad576bd0abba33194d05a985cc204cf6b9aed79b2e805062867e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
